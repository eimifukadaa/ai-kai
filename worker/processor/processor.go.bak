package processor

import (
	"context"
	"fmt"
	"image/png"
	"io"
	"log"
	"net/http"
	"os"
	"path/filepath"
	"strings"
	"sync"
	"time"

	"github.com/gen2brain/go-fitz"
	"github.com/google/generative-ai-go/genai"
	"github.com/ledongthuc/pdf"
	"github.com/pdfcpu/pdfcpu/pkg/api"
	"github.com/pdfcpu/pdfcpu/pkg/pdfcpu/model"
	"github.com/supabase-community/supabase-go"
	"google.golang.org/api/option"
	"os/exec"
)

type Job struct {
	ID         string    `json:"id"`
	DocumentID string    `json:"document_id"`
	UserID     string    `json:"user_id"`
	Status     string    `json:"status"`
	Attempts   int       `json:"attempts"`
	CreatedAt  time.Time `json:"created_at"`
}

type Document struct {
	ID          string `json:"id"`
	StoragePath string `json:"storage_path"`
}

type Processor struct {
	client      *supabase.Client
	apiUrl      string
	serviceKey  string
	genAIClient *genai.Client
}

func NewProcessor(client *supabase.Client, apiUrl, serviceKey string) *Processor {
	// Initialize Gemini Client
	apiKey := os.Getenv("GEMINI_API_KEY")
	ctx := context.Background()
	genClient, err := genai.NewClient(ctx, option.WithAPIKey(apiKey))
	if err != nil {
		log.Printf("Warning: Failed to create Gemini client: %v", err)
	}

	return &Processor{
		client:      client,
		apiUrl:      apiUrl,
		serviceKey:  serviceKey,
		genAIClient: genClient,
	}
}

func (p *Processor) ProcessJob(job Job) error {
	// 1. Get Document Info
	var docs []Document
	_, err := p.client.From("documents").Select("*", "exact", false).Eq("id", job.DocumentID).ExecuteTo(&docs)
	if err != nil || len(docs) == 0 {
		return fmt.Errorf("document not found: %v", err)
	}
	doc := docs[0]

	// 2. Download File
	downloadUrl := fmt.Sprintf("%s/storage/v1/object/kai_docs/%s", p.apiUrl, doc.StoragePath)
	req, _ := http.NewRequest("GET", downloadUrl, nil)
	req.Header.Set("Authorization", "Bearer "+p.serviceKey)

	resp, err := http.DefaultClient.Do(req)
	if err != nil {
		return fmt.Errorf("download failed: %v", err)
	}
	defer resp.Body.Close()

	if resp.StatusCode != 200 {
		b, _ := io.ReadAll(resp.Body)
		return fmt.Errorf("download error %d: %s", resp.StatusCode, string(b))
	}

	tempDir := os.TempDir()
	localPath := filepath.Join(tempDir, fmt.Sprintf("%s.pdf", doc.ID))
	outFile, err := os.Create(localPath)
	if err != nil {
		return err
	}
	_, err = io.Copy(outFile, resp.Body)
	outFile.Close()
	defer os.Remove(localPath)

	// 3. Get Page Count & Validate using ledongthuc/pdf
	pdfFile, r, err := pdf.Open(localPath)
	if err != nil {
		return fmt.Errorf("invalid pdf: %v", err)
	}
	defer pdfFile.Close()
	pageCount := r.NumPage()
	
	// Update total pages
	_, _, err = p.client.From("documents").Update(map[string]interface{}{"pages_total": pageCount}, "", "").Eq("id", doc.ID).Execute()
	if err != nil {
		log.Println("Error updating pages_total:", err)
	}

	// 4. Process Pages Sequentially (to avoid 429 Rate Limits)
	// The free tier has distinct rate limits (15 RPM), so parallel processing triggers 429s immediately.
	const maxConcurrency = 1 
	sem := make(chan struct{}, maxConcurrency)
	var wg sync.WaitGroup
	errChan := make(chan error, pageCount)

	for i := 1; i <= pageCount; i++ {
		wg.Add(1)
		go func(pageNum int) {
			defer wg.Done()
			sem <- struct{}{}        // Acquire token
			defer func() { <-sem }() // Release token

            // Extract Text using Go library
            pageText, err := p.extractTextGo(localPath, pageNum)
			if err != nil {
				log.Printf("extract error page %d: %v", pageNum, err)
			}
            
            // Fallback: If empty, try Tesseract OCR
            if len(strings.TrimSpace(pageText)) < 10 { 
                log.Printf("Page %d seems empty or image-based (len=%d). Attempting OCR...", pageNum, len(pageText))
                
                ocrText, errOCR := p.extractTextWithOCR(localPath, pageNum)
                if errOCR != nil {
                     log.Printf("❌ OCR failed for page %d: %v", pageNum, errOCR)
                } else {
                     log.Printf("✅ OCR success for page %d. Extracted %d chars", pageNum, len(ocrText))
                     pageText = ocrText
                }
            }


			// Save Page
			fmt.Printf("Saving page %d...\n", pageNum)
			_, _, err = p.client.From("document_pages").Insert(map[string]interface{}{
				"document_id": doc.ID,
				"page_number": pageNum,
				"text":        pageText,
			}, false, "", "", "exact").Execute()

			if err != nil {
				log.Printf("Failed to save page %d: %v", pageNum, err)
				errChan <- fmt.Errorf("page %d save failed: %w", pageNum, err)
				return
			}
			fmt.Printf("Page %d saved. Chunking...\n", pageNum)

			// Chunking & Embeddings & Batch Insert
			chunks := p.chunkText(pageText)
			fmt.Printf("Page %d chunks: %d\n", pageNum, len(chunks))
			if len(chunks) > 0 {
				var chunkInserts []map[string]interface{}
				
				// Generate embeddings
				fmt.Printf("Generating embeddings for page %d...\n", pageNum)
                embeddings, err := p.generateEmbeddings(chunks)
                if err != nil {
                     log.Printf("Embedding error page %d: %v", pageNum, err)
                } else {
					fmt.Printf("Generated %d embeddings for page %d\n", len(embeddings), pageNum)
				}

				for idx, content := range chunks {
					data := map[string]interface{}{
						"document_id": doc.ID,
						"page_number": pageNum,
						"chunk_index": idx,
						"content":     content,
					}
					if len(embeddings) > idx {
					    data["embedding"] = embeddings[idx]
					}
					
					chunkInserts = append(chunkInserts, data)
				}

				fmt.Printf("Inserting %d chunks for page %d...\n", len(chunkInserts), pageNum)
				_, _, err = p.client.From("document_chunks").Insert(chunkInserts, false, "", "", "exact").Execute()
				if err != nil {
					log.Printf("Failed to save chunks for page %d: %v", pageNum, err)
					fmt.Printf("INSERT ERROR: %v\n", err) 
				} else {
					fmt.Printf("Chunks inserted for page %d\n", pageNum)
				}
			}

			// Update Progress
			if pageNum%5 == 0 || pageNum == pageCount {
				p.client.From("documents").Update(map[string]interface{}{"pages_done": pageNum}, "", "").Eq("id", doc.ID).Execute()
			}

		}(i)
	}

	wg.Wait()
	close(errChan)

	if len(errChan) > 0 {
		return <-errChan 
	}

	return nil
}

// Replaced implementation with pure Go
func (p *Processor) extractTextGo(path string, pageNum int) (string, error) {
    // pdf.Open returns (file, reader, error)
    pdfFile, r, err := pdf.Open(path)
    if err != nil {
        return "", err
    }
    defer pdfFile.Close()
    
    if pageNum > r.NumPage() {
        return "", fmt.Errorf("page out of range")
    }
    
    pObj := r.Page(pageNum)
    content, err := pObj.GetPlainText(nil)
    if err != nil {
        return "", err 
    }
    return content, nil
}

// Extract text from image-based PDF using Tesseract OCR
func (p *Processor) extractTextWithOCR(pdfPath string, pageNum int) (string, error) {
	// Extract page as image using pdfcpu (pure Go, no DLL dependencies)
	conf := model.NewDefaultConfiguration()
	imgFiles, err := api.ExtractImagesFile(pdfPath, tempDir, []string{fmt.Sprintf("%d", pageNum)}, conf)
	if err != nil || len(imgFiles) == 0 {
		return "", fmt.Errorf("failed to extract page %d as image: %w", pageNum, err)
	}
	
	// Use the first extracted image
	imgPath := imgFiles[0]
	defer os.Remove(imgPath)

	// Call tesseract.exe directly to avoid library compatibility issues
	// Tesseract is installed at: C:\Program Files\Tesseract-OCR\tesseract.exe
	tesseractPath := "C:\\Program Files\\Tesseract-OCR\\tesseract.exe"
	outputPath := filepath.Join(tempDir, fmt.Sprintf("page_%d_out", pageNum))
	
	// Run tesseract: tesseract input.png output (without extension)
	cmd := exec.Command(tesseractPath, imgPath, outputPath)
	output, err := cmd.CombinedOutput()
	if err != nil {
		return "", fmt.Errorf("Tesseract OCR error: %w, output: %s", err, string(output))
	}
	
	// Read the output file (tesseract adds .txt extension)
	txtPath := outputPath + ".txt"
	defer os.Remove(txtPath)
	
	textBytes, err := os.ReadFile(txtPath)
	if err != nil {
		return "", fmt.Errorf("failed to read OCR output: %w", err)
	}

	return strings.TrimSpace(string(textBytes)), nil
}

// Removed legacy pdfcpu/ocr implementations


func (p *Processor) chunkText(text string) []string {
	const size = 1000 // Reduced specifically for embedding context window safety
	const overlap = 100
	var chunks []string

	runes := []rune(text)
	if len(runes) == 0 {
		return chunks
	}

	for i := 0; i < len(runes); i += (size - overlap) {
		end := i + size
		if end > len(runes) {
			end = len(runes)
		}
		chunks = append(chunks, string(runes[i:end]))
		if end == len(runes) {
			break
		}
	}
	return chunks
}

func (p *Processor) generateEmbeddings(texts []string) ([][]float32, error) {
    if p.genAIClient == nil {
        return nil, fmt.Errorf("genAI client not initialized")
    }
    if len(texts) == 0 {
        return nil, nil
    }

    model := p.genAIClient.EmbeddingModel("text-embedding-004")
    batch := model.NewBatch()
    for _, text := range texts {
        batch.AddContent(genai.Text(text))
    }
    
    ctx := context.Background()
    resp, err := model.BatchEmbedContents(ctx, batch)
    if err != nil {
        return nil, err
    }
    
    var results [][]float32
    for _, e := range resp.Embeddings {
        results = append(results, e.Values)
    }
    return results, nil
}
